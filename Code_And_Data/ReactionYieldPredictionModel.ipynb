{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c26fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt #data visualization\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split # Split data to train and test data(after merging in this case)\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# import libraries from tensorflow\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout,Input, BatchNormalization, LeakyReLU, ReLU\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.initializers import HeUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7a3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df = pd.read_excel(\"TrainingDataset.xlsx\")\n",
    "df = df.drop(['References'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df18a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Columns with missing values\n",
    "missing_columns = ['Activator (equiv.)', 'Time (h)']\n",
    "\n",
    "# 1. Imputation for numerical features (using mean or median)\n",
    "numerical_columns = ['Acid (equiv.)', 'Amine (equiv.)', 'Activator (equiv.)', 'Base (equiv.)', \n",
    "                     'Global Conc (M)', 'Temp (C)', 'Time (h)']\n",
    "\n",
    "# Create a SimpleImputer for numerical columns (using 'mean' strategy)\n",
    "imputer_num = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Apply the imputer to numerical columns\n",
    "df[numerical_columns] = imputer_num.fit_transform(df[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc20e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(columns=['Reaction_Yield'])\n",
    "y_train = df['Reaction_Yield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5cc1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_update = pd.read_excel(\"TestData.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1f8c5",
   "metadata": {},
   "source": [
    "## Categorical Encoding fitted on X_train, used(transformed) on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66c58978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# List of categorical columns\n",
    "categorical_columns = ['Acid (name)', 'Amine (name)', 'Activator (name)', 'Base (name)', 'Solvent']\n",
    "\n",
    "# Initialize a dictionary to store the label encoders for each column\n",
    "label_encoders = {}\n",
    "\n",
    "# Apply label encoding to each categorical column in both train and test data\n",
    "for col in categorical_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # Fit the label encoder on the training data\n",
    "    X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    \n",
    "    # Store the label encoder for later use\n",
    "    label_encoders[col] = label_encoder\n",
    "    \n",
    "    # Identify unseen labels in the test data\n",
    "    unseen_labels = X_test_update[~X_test_update[col].isin(label_encoder.classes_)][col].unique()\n",
    "    \n",
    "    # Generate new labels for unseen categories\n",
    "    new_labels = {label: i for i, label in enumerate(unseen_labels, start=len(label_encoder.classes_))}\n",
    "    \n",
    "    # Map unseen labels in the test set to new unique integers\n",
    "    X_test_update[col] = X_test_update[col].apply(lambda x: new_labels.get(x, x))\n",
    "    \n",
    "    # Append unseen labels to the label encoder's classes (though not strictly necessary anymore)\n",
    "    label_encoder.classes_ = np.append(label_encoder.classes_, list(new_labels.keys()))\n",
    "    \n",
    "    # Transform both known and new labels in the test set\n",
    "    X_test_update[col] = X_test_update[col].apply(lambda x: label_encoder.transform([x])[0] if x in label_encoder.classes_ else new_labels.get(x, x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb8f239",
   "metadata": {},
   "source": [
    "## Loading all Pickled Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc2310b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the representation learning model along with Gradient Boosting\n",
    "with open('rlgb_optuna.pkl', 'rb') as f:\n",
    "    loaded_regressor = pickle.load(f)\n",
    "    \n",
    "# Load the encoder model to generate latent representations of data\n",
    "with open('encoder_rlgb_optuna.pkl', 'rb') as f:\n",
    "    loaded_encoder = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e5ef2",
   "metadata": {},
   "source": [
    "## Predicting on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9638a66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#Extract learned representations from the encoder\n",
    "X_test_encoded = loaded_encoder.predict(X_test_update)\n",
    "\n",
    "# Use the loaded model to predict on X_test_encoded\n",
    "y_pred_loaded = loaded_regressor.predict(X_test_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
